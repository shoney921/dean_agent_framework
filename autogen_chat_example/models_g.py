from typing import List, Sequence
import asyncio

from autogen_core.models import ModelInfo
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination
from autogen_agentchat.teams import SelectorGroupChat
from autogen_agentchat.ui import Console
from autogen_ext.models.openai import OpenAIChatCompletionClient


# Mock tools - ë°ëª¨ìš© ë„êµ¬ í•¨ìˆ˜ë“¤
def search_web_tool(query: str) -> str:
    """ì›¹ ê²€ìƒ‰ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ë„êµ¬"""
    if "2006-2007" in query:
        return """2006-2007 ì‹œì¦Œ ë§ˆì´ì• ë¯¸ íˆíŠ¸ ì„ ìˆ˜ë“¤ì˜ ì´ ë“ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
        ìš°ë„ë‹ˆìŠ¤ í•˜ìŠ¬ë ˜: 844ì 
        ë“œì›¨ì¸ ì›¨ì´ë“œ: 1397ì 
        ì œì„ìŠ¤ í¬ì§€: 550ì 
        ...
        """
    elif "2007-2008" in query:
        return "ë§ˆì´ì• ë¯¸ íˆíŠ¸ 2007-2008 ì‹œì¦Œ ë“œì›¨ì¸ ì›¨ì´ë“œì˜ ì´ ë¦¬ë°”ìš´ë“œ ìˆ˜ëŠ” 214ê°œì…ë‹ˆë‹¤."
    elif "2008-2009" in query:
        return "ë§ˆì´ì• ë¯¸ íˆíŠ¸ 2008-2009 ì‹œì¦Œ ë“œì›¨ì¸ ì›¨ì´ë“œì˜ ì´ ë¦¬ë°”ìš´ë“œ ìˆ˜ëŠ” 398ê°œì…ë‹ˆë‹¤."
    return "ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


def percentage_change_tool(start: float, end: float) -> float:
    """í¼ì„¼íŠ¸ ë³€í™”ë¥¼ ê³„ì‚°í•˜ëŠ” ë„êµ¬"""
    return ((end - start) / start) * 100


async def main() -> None:
    # Gemini ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    model_client = OpenAIChatCompletionClient(
        model="gemini-2.5-flash",
        model_info=ModelInfo(
            vision=True, 
            function_calling=True, 
            json_output=True, 
            family="unknown", 
            structured_output=True
        ),
        api_key="AIzaSyAsh2RsHqQxUMiMxEdNv6moXnw-jkAn0NU",
    )
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì •ë³´ ì¶œë ¥
    print("=" * 80)
    print("ëª¨ë¸ ì •ë³´ í™•ì¸")
    print("=" * 80)
    
    # ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ë“¤
    available_gemini_models = [
        "gemini-1.5-flash",
        "gemini-1.5-pro", 
        "gemini-2.0-flash-exp",
        "gemini-2.0-flash-lite",
        "gemini-1.5-flash-8b",
        "gemini-1.5-pro-002"
    ]
    
    print("ğŸ“‹ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ë“¤:")
    print("-" * 50)
    
    for i, model in enumerate(available_gemini_models, 1):
        status = "âœ… í˜„ì¬ ì‚¬ìš© ì¤‘" if model == "gemini-2.0-flash-lite" else "   "
        print(f"{status} {i}. {model}")
    
    print("-" * 50)
    print(f"í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: gemini-2.0-flash-lite")
    print("ğŸ’¡ ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì½”ë“œì—ì„œ model íŒŒë¼ë¯¸í„°ë¥¼ ë³€ê²½í•˜ì„¸ìš”.")
    print("=" * 80)

    # 1. Web Search Agent - ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì—ì´ì „íŠ¸
    web_search_agent = AssistantAgent(
        "WebSearchAgent",
        description="ìŠ¤í¬ì¸  í†µê³„ì— ëŒ€í•œ ì›¹ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.",
        tools=[search_web_tool],
        model_client=model_client,
        system_message="""
        ë‹¹ì‹ ì€ ìŠ¤í¬ì¸  í†µê³„ë¥¼ ì°¾ëŠ” ë° íŠ¹í™”ëœ ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
        ìš”ì²­ëœ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•´ search_web_toolì„ ì‚¬ìš©í•˜ì„¸ìš”.
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì œê³µí•œ í›„, ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš° DataAnalystAgentì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.
        í•œ ë²ˆì— í•˜ë‚˜ì˜ ê²€ìƒ‰ë§Œ ìˆ˜í–‰í•˜ì„¸ìš”.
        """,
    )

    # 2. Data Analyst Agent - ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì—ì´ì „íŠ¸
    data_analyst_agent = AssistantAgent(
        "DataAnalystAgent",
        description="ê³„ì‚° ë° ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.",
        model_client=model_client,
        tools=[percentage_change_tool],
        system_message="""
        ë‹¹ì‹ ì€ í†µê³„ì  ê³„ì‚°ì— íŠ¹í™”ëœ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
        ë°ì´í„°ê°€ í•„ìš”í•  ë•ŒëŠ” WebSearchAgentì—ê²Œ ê²€ìƒ‰ì„ ìš”ì²­í•˜ì„¸ìš”.
        í¼ì„¼íŠ¸ ë³€í™”ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ percentage_change_toolì„ ì‚¬ìš©í•˜ì„¸ìš”.
        ëª¨ë“  ê³„ì‚°ì„ ì™„ë£Œí•œ í›„, ìµœì¢… ìš”ì•½ì„ ì œê³µí•˜ê³  "TERMINATE"ë¼ê³  ë§í•˜ì„¸ìš”.
        """,
    )

    # ì¢…ë£Œ ì¡°ê±´ ì„¤ì •
    termination = TextMentionTermination("TERMINATE") | MaxMessageTermination(max_messages=25)

    # SelectorGroupChat íŒ€ ìƒì„±
    team = SelectorGroupChat(
        participants=[web_search_agent, data_analyst_agent],
        termination_condition=termination,
        model_client=model_client,
    )

    # ì‘ì—… ì‹¤í–‰
    print("=" * 80)
    print("SelectorGroupChat ì˜ˆì‹œ ì‹œì‘")
    print("=" * 80)
    
    task = """2006-2007 ì‹œì¦Œì— ê°€ì¥ ë†’ì€ ë“ì ì„ ê¸°ë¡í•œ ë§ˆì´ì• ë¯¸ íˆíŠ¸ ì„ ìˆ˜ëŠ” ëˆ„êµ¬ì˜€ê³ , 
    ê·¸ì˜ 2007-2008 ì‹œì¦Œê³¼ 2008-2009 ì‹œì¦Œ ê°„ ì´ ë¦¬ë°”ìš´ë“œ ìˆ˜ì˜ í¼ì„¼íŠ¸ ë³€í™”ëŠ” ì–¼ë§ˆì¸ê°€ìš”?"""
    
    print(f"\nì§ˆë¬¸: {task}\n")
    print("=" * 80)
    
    # ìŠ¤íŠ¸ë¦¼ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ì§„í–‰ ê³¼ì • í™•ì¸
    stream = team.run_stream(task=task)
    
    async for message in stream:
        if hasattr(message, 'source') and hasattr(message, 'content'):
            print(f"\n---------- {message.source} ----------")
            print(message.content)
    
    print("\n" + "=" * 80)
    print("ì‘ì—… ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())