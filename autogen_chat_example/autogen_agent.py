"""
AutoGen ê¸°ë°˜ ì›¹ ê²€ìƒ‰ ë° ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ Gemini ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì›¹ ê²€ìƒ‰ê³¼ ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ”
ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.
"""

import asyncio
import os
from typing import List

from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination
from autogen_agentchat.teams import SelectorGroupChat
from autogen_core.models import ModelInfo
from autogen_ext.models.openai import OpenAIChatCompletionClient
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ============================================================================
# ìƒìˆ˜ ì •ì˜
# ============================================================================

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyAsh2RsHqQxUMiMxEdNv6moXnw-jkAn0NU")
DEFAULT_MODEL = "gemini-2.5-flash"
MAX_MESSAGES = 25
MAX_SEARCH_RESULTS = 5

AVAILABLE_GEMINI_MODELS = [
    "gemini-1.5-flash",
    "gemini-1.5-pro",
    "gemini-2.0-flash-exp",
    "gemini-2.0-flash-lite",
    "gemini-1.5-flash-8b",
    "gemini-1.5-pro-002"
]

WEB_SEARCH_AGENT_SYSTEM_MESSAGE = """
ë‹¹ì‹ ì€ ìŠ¤í¬ì¸  í†µê³„ë¥¼ ì°¾ëŠ” ë° íŠ¹í™”ëœ ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ìš”ì²­ëœ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•´ search_web_toolì„ ì‚¬ìš©í•˜ì„¸ìš”.
ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì œê³µí•œ í›„, ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš° DataAnalystAgentì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.
í•œ ë²ˆì— í•˜ë‚˜ì˜ ê²€ìƒ‰ë§Œ ìˆ˜í–‰í•˜ì„¸ìš”.
"""

DATA_ANALYST_AGENT_SYSTEM_MESSAGE = """
ë‹¹ì‹ ì€ í†µê³„ì  ê³„ì‚°ì— íŠ¹í™”ëœ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ë°ì´í„°ê°€ í•„ìš”í•  ë•ŒëŠ” WebSearchAgentì—ê²Œ ê²€ìƒ‰ì„ ìš”ì²­í•˜ì„¸ìš”.
í¼ì„¼íŠ¸ ë³€í™”ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ percentage_change_toolì„ ì‚¬ìš©í•˜ì„¸ìš”.
ëª¨ë“  ê³„ì‚°ì„ ì™„ë£Œí•œ í›„, ìµœì¢… ìš”ì•½ì„ ì œê³µí•˜ê³  "TERMINATE"ë¼ê³  ë§í•˜ì„¸ìš”.
"""


# ============================================================================
# ë„êµ¬ í•¨ìˆ˜ (Tools)
# ============================================================================

def search_web_tool(query: str) -> str:
    """
    Tavily APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë„êµ¬
    
    Args:
        query (str): ê²€ìƒ‰í•  ì¿¼ë¦¬ ë¬¸ìì—´
        
    Returns:
        str: ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•œ ë¬¸ìì—´
    """
    try:
        from tavily import TavilyClient
        
        tavily_api_key = os.getenv("TAVILY_API_KEY")
        
        if not tavily_api_key:
            return "âŒ TAVILY_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."
        
        tavily = TavilyClient(api_key=tavily_api_key)
        response = tavily.search(query, max_results=MAX_SEARCH_RESULTS)
        
        if not response.get('results'):
            return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        formatted_results = []
        for i, result in enumerate(response['results'], 1):
            formatted_results.append(
                f"{i}. {result.get('title', 'No title')}\n"
                f"   ì¶œì²˜: {result.get('url', 'No URL')}\n"
                f"   ë‚´ìš©: {result.get('content', 'No description')}\n"
            )
        
        return "\n".join(formatted_results)
        
    except ImportError as e:
        return f"í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {str(e)}\n'pip install tavily-python' ì„ ì‹¤í–‰í•˜ì„¸ìš”."
    except Exception as e:
        return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


def percentage_change_tool(start: float, end: float) -> float:
    """
    ë‘ ê°’ ì‚¬ì´ì˜ í¼ì„¼íŠ¸ ë³€í™”ë¥¼ ê³„ì‚°í•˜ëŠ” ë„êµ¬
    
    Args:
        start (float): ì‹œì‘ ê°’
        end (float): ì¢…ë£Œ ê°’
        
    Returns:
        float: í¼ì„¼íŠ¸ ë³€í™” ê°’
    """
    return ((end - start) / start) * 100


# ============================================================================
# ëª¨ë¸ ë° ì—ì´ì „íŠ¸ ì„¤ì • í•¨ìˆ˜
# ============================================================================

def create_model_client(model: str = DEFAULT_MODEL, api_key: str = GEMINI_API_KEY) -> OpenAIChatCompletionClient:
    """
    Gemini ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        model (str): ì‚¬ìš©í•  Gemini ëª¨ë¸ ì´ë¦„
        api_key (str): Gemini API í‚¤
        
    Returns:
        OpenAIChatCompletionClient: ì„¤ì •ëœ ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸
    """
    return OpenAIChatCompletionClient(
        model=model,
        model_info=ModelInfo(
            vision=True,
            function_calling=True,
            json_output=True,
            family="unknown",
            structured_output=True
        ),
        api_key=api_key,
    )


def create_web_search_agent(model_client: OpenAIChatCompletionClient) -> AssistantAgent:
    """
    ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        model_client: ì‚¬ìš©í•  ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸
        
    Returns:
        AssistantAgent: ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸
    """
    return AssistantAgent(
        "WebSearchAgent",
        description="ìŠ¤í¬ì¸  í†µê³„ì— ëŒ€í•œ ì›¹ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.",
        tools=[search_web_tool],
        model_client=model_client,
        system_message=WEB_SEARCH_AGENT_SYSTEM_MESSAGE,
    )


def create_data_analyst_agent(model_client: OpenAIChatCompletionClient) -> AssistantAgent:
    """
    ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        model_client: ì‚¬ìš©í•  ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸
        
    Returns:
        AssistantAgent: ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸
    """
    return AssistantAgent(
        "DataAnalystAgent",
        description="ê³„ì‚° ë° ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.",
        model_client=model_client,
        tools=[percentage_change_tool],
        system_message=DATA_ANALYST_AGENT_SYSTEM_MESSAGE,
    )


def create_team(
    agents: List[AssistantAgent],
    model_client: OpenAIChatCompletionClient,
    max_messages: int = MAX_MESSAGES
) -> SelectorGroupChat:
    """
    ë©€í‹° ì—ì´ì „íŠ¸ íŒ€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        agents: íŒ€ì— ì°¸ì—¬í•  ì—ì´ì „íŠ¸ ë¦¬ìŠ¤íŠ¸
        model_client: ì‚¬ìš©í•  ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸
        max_messages: ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜
        
    Returns:
        SelectorGroupChat: ì„¤ì •ëœ íŒ€
    """
    termination = TextMentionTermination("TERMINATE") | MaxMessageTermination(max_messages=max_messages)
    
    return SelectorGroupChat(
        participants=agents,
        termination_condition=termination,
        model_client=model_client,
    )


# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

def print_model_info(current_model: str = DEFAULT_MODEL) -> None:
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Args:
        current_model: í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì´ë¦„
    """
    print("=" * 80)
    print("ëª¨ë¸ ì •ë³´ í™•ì¸")
    print("=" * 80)
    print("ğŸ“‹ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ë“¤:")
    print("-" * 50)
    
    for i, model in enumerate(AVAILABLE_GEMINI_MODELS, 1):
        status = "âœ… í˜„ì¬ ì‚¬ìš© ì¤‘" if model == current_model else "   "
        print(f"{status} {i}. {model}")
    
    print("-" * 50)
    print(f"í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: {current_model}")
    print("ğŸ’¡ ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì½”ë“œì—ì„œ DEFAULT_MODEL ìƒìˆ˜ë¥¼ ë³€ê²½í•˜ì„¸ìš”.")
    print("=" * 80)


def print_section_header(title: str) -> None:
    """ì„¹ì…˜ í—¤ë”ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("\n" + "=" * 80)
    print(title)
    print("=" * 80)


async def run_team_task(team: SelectorGroupChat, task: str) -> None:
    """
    íŒ€ì— ì‘ì—…ì„ í• ë‹¹í•˜ê³  ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Args:
        team: ì‹¤í–‰í•  íŒ€
        task: ìˆ˜í–‰í•  ì‘ì—… ì„¤ëª…
    """
    print_section_header("SelectorGroupChat ì˜ˆì‹œ ì‹œì‘")
    print(f"\nì§ˆë¬¸: {task}\n")
    print("=" * 80)
    
    stream = team.run_stream(task=task)
    
    async for message in stream:
        if hasattr(message, 'source') and hasattr(message, 'content'):
            print(f"\n---------- {message.source} ----------")
            print(message.content)
    
    print_section_header("ì‘ì—… ì™„ë£Œ!")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================================================

async def main() -> None:
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # 1. ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    model_client = create_model_client()
    
    # 2. ëª¨ë¸ ì •ë³´ ì¶œë ¥
    print_model_info(DEFAULT_MODEL)
    
    # 3. ì—ì´ì „íŠ¸ ìƒì„±
    web_search_agent = create_web_search_agent(model_client)
    data_analyst_agent = create_data_analyst_agent(model_client)
    
    # 4. íŒ€ ìƒì„±
    team = create_team([web_search_agent, data_analyst_agent], model_client)
    
    # 5. ì‘ì—… ì‹¤í–‰
    # task = """2006-2007 ì‹œì¦Œì— ê°€ì¥ ë†’ì€ ë“ì ì„ ê¸°ë¡í•œ ë§ˆì´ì• ë¯¸ íˆíŠ¸ ì„ ìˆ˜ëŠ” ëˆ„êµ¬ì˜€ê³ , 
    # ê·¸ì˜ 2007-2008 ì‹œì¦Œê³¼ 2008-2009 ì‹œì¦Œ ê°„ ì´ ë¦¬ë°”ìš´ë“œ ìˆ˜ì˜ í¼ì„¼íŠ¸ ë³€í™”ëŠ” ì–¼ë§ˆì¸ê°€ìš”?"""
    task = "lg cns ì£¼ì‹ ì „ë§ì€ ì–´ë–¤ì§€ ì•Œì•„ë´ì¤˜"
    
    await run_team_task(team, task)


if __name__ == "__main__":
    asyncio.run(main())