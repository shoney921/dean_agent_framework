"""
μ—μ΄μ „νΈ κΈ°λ³Έ μ„¤μ • λ° κ³µν†µ ν•¨μ

μ΄ λ¨λ“μ€ λ¨λ“  μ—μ΄μ „νΈκ°€ κ³µν†µμΌλ΅ μ‚¬μ©ν•λ” λ¨λΈ ν΄λΌμ΄μ–ΈνΈ μƒμ„± λ“±μ κΈ°λ¥μ„ μ κ³µν•©λ‹λ‹¤.
"""

from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_core.models import ModelInfo

from src.core.config import DEFAULT_MODEL, GEMINI_API_KEY, AVAILABLE_GEMINI_MODELS


def create_model_client(model: str = DEFAULT_MODEL, api_key: str = GEMINI_API_KEY) -> OpenAIChatCompletionClient:
    """
    Gemini λ¨λΈ ν΄λΌμ΄μ–ΈνΈλ¥Ό μƒμ„±ν•©λ‹λ‹¤.
    
    Args:
        model (str): μ‚¬μ©ν•  Gemini λ¨λΈ μ΄λ¦„
        api_key (str): Gemini API ν‚¤
        
    Returns:
        OpenAIChatCompletionClient: μ„¤μ •λ λ¨λΈ ν΄λΌμ΄μ–ΈνΈ
    """
    return OpenAIChatCompletionClient(
        model=model,
        model_info=ModelInfo(
            vision=True,
            function_calling=True,
            json_output=True,
            family="unknown",
            structured_output=True
        ),
        api_key=api_key,
    )


def print_model_info(current_model: str = DEFAULT_MODEL) -> None:
    """
    μ‚¬μ© κ°€λ¥ν• Gemini λ¨λΈ μ •λ³΄λ¥Ό μ¶λ ¥ν•©λ‹λ‹¤.
    
    Args:
        current_model: ν„μ¬ μ‚¬μ© μ¤‘μΈ λ¨λΈ μ΄λ¦„
    """
    print("=" * 80)
    print("λ¨λΈ μ •λ³΄ ν™•μΈ")
    print("=" * 80)
    print("π“‹ μΌλ°μ μΌλ΅ μ‚¬μ© κ°€λ¥ν• Gemini λ¨λΈλ“¤:")
    print("-" * 50)
    
    for i, model in enumerate(AVAILABLE_GEMINI_MODELS, 1):
        status = "β… ν„μ¬ μ‚¬μ© μ¤‘" if model == current_model else "   "
        print(f"{status} {i}. {model}")
    
    print("-" * 50)
    print(f"ν„μ¬ μ‚¬μ© μ¤‘μΈ λ¨λΈ: {current_model}")
    print("π’΅ λ‹¤λ¥Έ λ¨λΈμ„ μ‚¬μ©ν•λ ¤λ©΄ src/core/config.pyμ—μ„ DEFAULT_MODEL μƒμλ¥Ό λ³€κ²½ν•μ„Έμ”.")
    print("=" * 80)

