"""
LangChain ì—ì´ì „íŠ¸ ê°„ ë©”ì‹œì§€ ì£¼ê³ ë°›ê¸° ìƒ˜í”Œ
GEMINI_API_KEYë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê°œì˜ ì—ì´ì „íŠ¸ê°€ ëŒ€í™”í•˜ëŠ” ì˜ˆì œ
"""

import os
from typing import List, Dict, Any
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import HumanMessage, AIMessage, SystemMessage
from langchain.memory import ConversationBufferMemory
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain.prompts import PromptTemplate

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class LangChainAgent:
    """LangChainì„ ì‚¬ìš©í•œ AI ì—ì´ì „íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, role: str, model_name: str = "gemini-2.0-flash-exp"):
        """
        ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        
        Args:
            name: ì—ì´ì „íŠ¸ ì´ë¦„
            role: ì—ì´ì „íŠ¸ ì—­í• 
            model_name: ì‚¬ìš©í•  ëª¨ë¸ëª…
        """
        self.name = name
        self.role = role
        self.model_name = model_name
        
        # Gemini API í‚¤ í™•ì¸
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Gemini ëª¨ë¸ ì´ˆê¸°í™”
        self.llm = ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=api_key,
            temperature=0.7,
            max_output_tokens=1024
        )
        
        # ëŒ€í™” ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.system_prompt = f"""
        ë‹¹ì‹ ì€ {self.name}ì…ë‹ˆë‹¤. ì—­í• : {self.role}
        
        ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ ëŒ€í™”í•˜ì„¸ìš”:
        1. ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”
        2. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”
        3. ì§ˆë¬¸ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
        4. ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì™€ í˜‘ë ¥í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”
        """
    
    def get_response(self, message: str, context: str = "") -> str:
        """
        ë©”ì‹œì§€ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
        
        Args:
            message: ì…ë ¥ ë©”ì‹œì§€
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            ì—ì´ì „íŠ¸ì˜ ì‘ë‹µ
        """
        try:
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                SystemMessage(content=self.system_prompt),
                HumanMessage(content=f"{context}\n{message}" if context else message)
            ]
            
            # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            chat_history = self.memory.chat_memory.messages
            if chat_history:
                messages = [SystemMessage(content=self.system_prompt)] + chat_history + [HumanMessage(content=message)]
            
            # ì‘ë‹µ ìƒì„±
            response = self.llm.invoke(messages)
            
            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            self.memory.chat_memory.add_user_message(message)
            self.memory.chat_memory.add_ai_message(response.content)
            
            return response.content
            
        except Exception as e:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """ëŒ€í™” ê¸°ë¡ ë°˜í™˜"""
        history = []
        messages = self.memory.chat_memory.messages
        
        for i in range(0, len(messages), 2):
            if i + 1 < len(messages):
                history.append({
                    "user": messages[i].content,
                    "assistant": messages[i + 1].content
                })
        
        return history


class LangChainAgentTeam:
    """ì—¬ëŸ¬ LangChain ì—ì´ì „íŠ¸ê°€ í˜‘ë ¥í•˜ëŠ” íŒ€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """íŒ€ ì´ˆê¸°í™”"""
        self.agents = {}
        self.conversation_log = []
    
    def add_agent(self, agent: LangChainAgent):
        """ì—ì´ì „íŠ¸ ì¶”ê°€"""
        self.agents[agent.name] = agent
    
    def start_conversation(self, initial_message: str, max_rounds: int = 5) -> List[Dict[str, Any]]:
        """
        ì—ì´ì „íŠ¸ ê°„ ëŒ€í™” ì‹œì‘
        
        Args:
            initial_message: ì´ˆê¸° ë©”ì‹œì§€
            max_rounds: ìµœëŒ€ ëŒ€í™” ë¼ìš´ë“œ ìˆ˜
            
        Returns:
            ëŒ€í™” ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
        """
        if not self.agents:
            raise ValueError("ì—ì´ì „íŠ¸ê°€ ì¶”ê°€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        agent_names = list(self.agents.keys())
        current_message = initial_message
        conversation = []
        
        print(f"ğŸš€ ëŒ€í™” ì‹œì‘: {initial_message}")
        print("=" * 50)
        
        for round_num in range(max_rounds):
            print(f"\nğŸ“ ë¼ìš´ë“œ {round_num + 1}")
            
            for agent_name in agent_names:
                agent = self.agents[agent_name]
                
                # ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„±
                response = agent.get_response(current_message)
                
                # ëŒ€í™” ê¸°ë¡ ì €ì¥
                conversation_entry = {
                    "round": round_num + 1,
                    "agent": agent_name,
                    "role": agent.role,
                    "message": current_message,
                    "response": response
                }
                conversation.append(conversation_entry)
                
                print(f"ğŸ¤– {agent_name} ({agent.role}): {response}")
                
                # ë‹¤ìŒ ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                current_message = response
            
            print("-" * 30)
        
        self.conversation_log.extend(conversation)
        return conversation


def create_sample_agents() -> LangChainAgentTeam:
    """ìƒ˜í”Œ ì—ì´ì „íŠ¸ íŒ€ ìƒì„±"""
    team = LangChainAgentTeam()
    
    # ë°ì´í„° ë¶„ì„ê°€ ì—ì´ì „íŠ¸
    data_analyst = LangChainAgent(
        name="ë°ì´í„°ë¶„ì„ê°€",
        role="ë°ì´í„° ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì „ë¬¸ê°€",
        model_name="gemini-2.0-flash-exp"
    )
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨ì„¤í„´íŠ¸ ì—ì´ì „íŠ¸
    business_consultant = LangChainAgent(
        name="ë¹„ì¦ˆë‹ˆìŠ¤ì»¨ì„¤í„´íŠ¸",
        role="ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ë° ì˜ì‚¬ê²°ì • ì§€ì› ì „ë¬¸ê°€",
        model_name="gemini-2.0-flash-exp"
    )
    
    # ê¸°ìˆ  ì „ë¬¸ê°€ ì—ì´ì „íŠ¸
    tech_expert = LangChainAgent(
        name="ê¸°ìˆ ì „ë¬¸ê°€",
        role="ê¸°ìˆ  ì•„í‚¤í…ì²˜ ë° êµ¬í˜„ ì „ë¬¸ê°€",
        model_name="gemini-2.0-flash-exp"
    )
    
    team.add_agent(data_analyst)
    team.add_agent(business_consultant)
    team.add_agent(tech_expert)
    
    return team


def run_sample_conversation():
    """ìƒ˜í”Œ ëŒ€í™” ì‹¤í–‰"""
    try:
        print("ğŸ¯ LangChain ì—ì´ì „íŠ¸ íŒ€ ëŒ€í™” ìƒ˜í”Œ ì‹œì‘")
        print("=" * 60)
        
        # ì—ì´ì „íŠ¸ íŒ€ ìƒì„±
        team = create_sample_agents()
        
        # ì´ˆê¸° ë©”ì‹œì§€ ì„¤ì •
        initial_message = """
        ìš°ë¦¬ íšŒì‚¬ì—ì„œ ìƒˆë¡œìš´ AI ê¸°ë°˜ ê³ ê° ì„œë¹„ìŠ¤ í”Œë«í¼ì„ êµ¬ì¶•í•˜ë ¤ê³  í•©ë‹ˆë‹¤. 
        ì´ í”„ë¡œì íŠ¸ì— ëŒ€í•´ ê°ìì˜ ì „ë¬¸ ë¶„ì•¼ ê´€ì ì—ì„œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
        """
        
        # ëŒ€í™” ì‹œì‘
        conversation = team.start_conversation(initial_message, max_rounds=3)
        
        print("\n" + "=" * 60)
        print("âœ… ëŒ€í™” ì™„ë£Œ!")
        print(f"ì´ {len(conversation)}ê°œì˜ ë©”ì‹œì§€ê°€ êµí™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return conversation
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


if __name__ == "__main__":
    # ìƒ˜í”Œ ëŒ€í™” ì‹¤í–‰
    run_sample_conversation()
